{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNno0XE5Rtk2C4W+4h7h3Li",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Minhtrna/9.5AI_techday/blob/main/imto3dv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYVHDmzPT0XB",
        "outputId": "b33aa4f2-8bc5-4841-a68e-0187da6d853d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stable-fast-3d'...\n",
            "remote: Enumerating objects: 89, done.\u001b[K\n",
            "remote: Total 89 (delta 0), reused 0 (delta 0), pack-reused 89 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (89/89), 3.28 MiB | 7.86 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://huggingface.co/spaces/stabilityai/stable-fast-3d"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd stable-fast-3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uAKa6e9Ue3r",
        "outputId": "0b03c4d0-52a0-4e66-833d-5bc1f52f1d64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stable-fast-3d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8HQCU4AUjdV",
        "outputId": "b78d707b-503c-4a4d-d831-d7fc97a91ea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py\tdemo_files  LICENSE.md\tload  README.md  requirements.txt  sf3d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U setuptools==69.5.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chaTqtDQg0XL",
        "outputId": "4ce87925-c7dd-48a8-9009-06964b5291c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools==69.5.1 in /usr/local/lib/python3.10/dist-packages (69.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wheel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUHTPKiPhDUk",
        "outputId": "3dcbd91b-b69b-44f9-a0c9-324da86b0806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.44.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -r requirements.txt -q"
      ],
      "metadata": {
        "id": "SoiC01jlU5NI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f3e2b30-8bc0-43c3-f842-b88ddf1f3d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m694.7/694.7 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m989.8/989.8 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.2/226.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m118.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.3.1 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\n",
            "torchaudio 2.4.0+cu121 requires torch==2.4.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio -q"
      ],
      "metadata": {
        "id": "HCs8nMCXZo0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "requires a token generated from https://huggingface.co/settings/tokens  \n",
        "also u need to fill in the access form in this link : https://huggingface.co/stabilityai/stable-fast-3d"
      ],
      "metadata": {
        "id": "RJMew0-cc3yF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrkE6PRxhNwL",
        "outputId": "030dbb87-6a89-4510-8de4-70fed497b2d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: fineGrained).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chỉnh sửa app.py để có giao diện khác"
      ],
      "metadata": {
        "id": "v5cDBCyMGttD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "import time\n",
        "from functools import lru_cache\n",
        "from typing import Any\n",
        "\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import rembg\n",
        "import torch\n",
        "from gradio_litmodel3d import LitModel3D\n",
        "from PIL import Image\n",
        "\n",
        "import sf3d.utils as sf3d_utils\n",
        "from sf3d.system import SF3D\n",
        "\n",
        "rembg_session = rembg.new_session()\n",
        "\n",
        "COND_WIDTH = 512\n",
        "COND_HEIGHT = 512\n",
        "COND_DISTANCE = 1.6\n",
        "COND_FOVY_DEG = 40\n",
        "BACKGROUND_COLOR = [0.5, 0.5, 0.5]\n",
        "\n",
        "# Cached. Doesn't change\n",
        "c2w_cond = sf3d_utils.default_cond_c2w(COND_DISTANCE)\n",
        "intrinsic, intrinsic_normed_cond = sf3d_utils.create_intrinsic_from_fov_deg(\n",
        "    COND_FOVY_DEG, COND_HEIGHT, COND_WIDTH\n",
        ")\n",
        "\n",
        "\n",
        "model = SF3D.from_pretrained(\n",
        "    \"stabilityai/stable-fast-3d\",\n",
        "    config_name=\"config.yaml\",\n",
        "    weight_name=\"model.safetensors\",\n",
        ")\n",
        "model.eval().cuda()\n",
        "example_files = [\n",
        "    os.path.join(\"demo_files/examples\", f) for f in os.listdir(\"demo_files/examples\")\n",
        "]\n",
        "\n",
        "\n",
        "def run_model(input_image):\n",
        "    start = time.time()\n",
        "    with torch.no_grad():\n",
        "        with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "            model_batch = create_batch(input_image)\n",
        "            model_batch = {k: v.cuda() for k, v in model_batch.items()}\n",
        "            trimesh_mesh, _glob_dict = model.generate_mesh(model_batch, 1024)\n",
        "            trimesh_mesh = trimesh_mesh[0]\n",
        "\n",
        "    # Create new tmp file\n",
        "    tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".glb\")\n",
        "\n",
        "    trimesh_mesh.export(tmp_file.name, file_type=\"glb\", include_normals=True)\n",
        "\n",
        "    print(\"Generation took:\", time.time() - start, \"s\")\n",
        "\n",
        "    return tmp_file.name\n",
        "\n",
        "\n",
        "def create_batch(input_image: Image) -> dict[str, Any]:\n",
        "    img_cond = (\n",
        "        torch.from_numpy(\n",
        "            np.asarray(input_image.resize((COND_WIDTH, COND_HEIGHT))).astype(np.float32)\n",
        "            / 255.0\n",
        "        )\n",
        "        .float()\n",
        "        .clip(0, 1)\n",
        "    )\n",
        "    mask_cond = img_cond[:, :, -1:]\n",
        "    rgb_cond = torch.lerp(\n",
        "        torch.tensor(BACKGROUND_COLOR)[None, None, :], img_cond[:, :, :3], mask_cond\n",
        "    )\n",
        "\n",
        "    batch_elem = {\n",
        "        \"rgb_cond\": rgb_cond,\n",
        "        \"mask_cond\": mask_cond,\n",
        "        \"c2w_cond\": c2w_cond.unsqueeze(0),\n",
        "        \"intrinsic_cond\": intrinsic.unsqueeze(0),\n",
        "        \"intrinsic_normed_cond\": intrinsic_normed_cond.unsqueeze(0),\n",
        "    }\n",
        "    # Add batch dim\n",
        "    batched = {k: v.unsqueeze(0) for k, v in batch_elem.items()}\n",
        "    return batched\n",
        "\n",
        "\n",
        "@lru_cache\n",
        "def checkerboard(squares: int, size: int, min_value: float = 0.5):\n",
        "    base = np.zeros((squares, squares)) + min_value\n",
        "    base[1::2, ::2] = 1\n",
        "    base[::2, 1::2] = 1\n",
        "\n",
        "    repeat_mult = size // squares\n",
        "    return (\n",
        "        base.repeat(repeat_mult, axis=0)\n",
        "        .repeat(repeat_mult, axis=1)[:, :, None]\n",
        "        .repeat(3, axis=-1)\n",
        "    )\n",
        "\n",
        "\n",
        "def remove_background(input_image: Image) -> Image:\n",
        "    return rembg.remove(input_image, session=rembg_session)\n",
        "\n",
        "\n",
        "def resize_foreground(\n",
        "    image: Image,\n",
        "    ratio: float,\n",
        ") -> Image:\n",
        "    image = np.array(image)\n",
        "    assert image.shape[-1] == 4\n",
        "    alpha = np.where(image[..., 3] > 0)\n",
        "    y1, y2, x1, x2 = (\n",
        "        alpha[0].min(),\n",
        "        alpha[0].max(),\n",
        "        alpha[1].min(),\n",
        "        alpha[1].max(),\n",
        "    )\n",
        "    # crop the foreground\n",
        "    fg = image[y1:y2, x1:x2]\n",
        "    # pad to square\n",
        "    size = max(fg.shape[0], fg.shape[1])\n",
        "    ph0, pw0 = (size - fg.shape[0]) // 2, (size - fg.shape[1]) // 2\n",
        "    ph1, pw1 = size - fg.shape[0] - ph0, size - fg.shape[1] - pw0\n",
        "    new_image = np.pad(\n",
        "        fg,\n",
        "        ((ph0, ph1), (pw0, pw1), (0, 0)),\n",
        "        mode=\"constant\",\n",
        "        constant_values=((0, 0), (0, 0), (0, 0)),\n",
        "    )\n",
        "\n",
        "    # compute padding according to the ratio\n",
        "    new_size = int(new_image.shape[0] / ratio)\n",
        "    # pad to size, double side\n",
        "    ph0, pw0 = (new_size - size) // 2, (new_size - size) // 2\n",
        "    ph1, pw1 = new_size - size - ph0, new_size - size - pw0\n",
        "    new_image = np.pad(\n",
        "        new_image,\n",
        "        ((ph0, ph1), (pw0, pw1), (0, 0)),\n",
        "        mode=\"constant\",\n",
        "        constant_values=((0, 0), (0, 0), (0, 0)),\n",
        "    )\n",
        "    new_image = Image.fromarray(new_image, mode=\"RGBA\").resize(\n",
        "        (COND_WIDTH, COND_HEIGHT)\n",
        "    )\n",
        "    return new_image\n",
        "\n",
        "\n",
        "def square_crop(input_image: Image) -> Image:\n",
        "    # Perform a center square crop\n",
        "    min_size = min(input_image.size)\n",
        "    left = (input_image.size[0] - min_size) // 2\n",
        "    top = (input_image.size[1] - min_size) // 2\n",
        "    right = (input_image.size[0] + min_size) // 2\n",
        "    bottom = (input_image.size[1] + min_size) // 2\n",
        "    return input_image.crop((left, top, right, bottom)).resize(\n",
        "        (COND_WIDTH, COND_HEIGHT)\n",
        "    )\n",
        "\n",
        "\n",
        "def show_mask_img(input_image: Image) -> Image:\n",
        "    img_numpy = np.array(input_image)\n",
        "    alpha = img_numpy[:, :, 3] / 255.0\n",
        "    chkb = checkerboard(32, 512) * 255\n",
        "    new_img = img_numpy[..., :3] * alpha[:, :, None] + chkb * (1 - alpha[:, :, None])\n",
        "    return Image.fromarray(new_img.astype(np.uint8), mode=\"RGB\")\n",
        "\n",
        "\n",
        "def run_button(run_btn, input_image, background_state, foreground_ratio):\n",
        "    if run_btn == \"Run\":\n",
        "        glb_file: str = run_model(background_state)\n",
        "\n",
        "        return (\n",
        "            gr.update(),\n",
        "            gr.update(),\n",
        "            gr.update(),\n",
        "            gr.update(),\n",
        "            gr.update(value=glb_file, visible=True),\n",
        "            gr.update(visible=True),\n",
        "        )\n",
        "    elif run_btn == \"Remove Background\":\n",
        "        rem_removed = remove_background(input_image)\n",
        "\n",
        "        sqr_crop = square_crop(rem_removed)\n",
        "        fr_res = resize_foreground(sqr_crop, foreground_ratio)\n",
        "\n",
        "        return (\n",
        "            gr.update(value=\"Run\", visible=True),\n",
        "            sqr_crop,\n",
        "            fr_res,\n",
        "            gr.update(value=show_mask_img(fr_res), visible=True),\n",
        "            gr.update(value=None, visible=False),\n",
        "            gr.update(visible=False),\n",
        "        )\n",
        "\n",
        "\n",
        "def requires_bg_remove(image, fr):\n",
        "    if image is None:\n",
        "        return (\n",
        "            gr.update(visible=False, value=\"Run\"),\n",
        "            None,\n",
        "            None,\n",
        "            gr.update(value=None, visible=False),\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "        )\n",
        "    alpha_channel = np.array(image.getchannel(\"A\"))\n",
        "    min_alpha = alpha_channel.min()\n",
        "\n",
        "    if min_alpha == 0:\n",
        "        print(\"Already has alpha\")\n",
        "        sqr_crop = square_crop(image)\n",
        "        fr_res = resize_foreground(sqr_crop, fr)\n",
        "        return (\n",
        "            gr.update(value=\"Run\", visible=True),\n",
        "            sqr_crop,\n",
        "            fr_res,\n",
        "            gr.update(value=show_mask_img(fr_res), visible=True),\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "        )\n",
        "    return (\n",
        "        gr.update(value=\"Remove Background\", visible=True),\n",
        "        None,\n",
        "        None,\n",
        "        gr.update(value=None, visible=False),\n",
        "        gr.update(visible=False),\n",
        "        gr.update(visible=False),\n",
        "    )\n",
        "\n",
        "\n",
        "def update_foreground_ratio(img_proc, fr):\n",
        "    foreground_res = resize_foreground(img_proc, fr)\n",
        "    return (\n",
        "        foreground_res,\n",
        "        gr.update(value=show_mask_img(foreground_res)),\n",
        "    )\n",
        "\n",
        "\n",
        "with gr.Blocks(css=\"footer{display:none !important}\", title= 'Imgto3D') as demo:\n",
        "    img_proc_state = gr.State()\n",
        "    background_remove_state = gr.State()\n",
        "    gr.Markdown(\n",
        "            \"\"\"\n",
        "            # Image to 3D Model base on Stable-fast-3D\n",
        "            \"\"\")\n",
        "    with gr.Row():\n",
        "        gr.Image(value=\"https://raw.githubusercontent.com/Minhtrna/9.5AI_techday/main/logo3.png\",show_label=False,width=100, height=100, show_download_button=False,show_fullscreen_button= False, container= False) # Display the logo\n",
        "    with gr.Row(variant=\"panel\"):\n",
        "        with gr.Column():\n",
        "            with gr.Row():\n",
        "                input_img = gr.Image(\n",
        "                    type=\"pil\", label=\"Input Image\", sources=\"upload\", image_mode=\"RGBA\"\n",
        "                )\n",
        "                preview_removal = gr.Image(\n",
        "                    label=\"Preview Background Removal\",\n",
        "                    type=\"pil\",\n",
        "                    image_mode=\"RGB\",\n",
        "                    interactive=False,\n",
        "                    visible=False,\n",
        "                )\n",
        "\n",
        "            foreground_ratio = gr.Slider(\n",
        "                label=\"Foreground Ratio\",\n",
        "                minimum=0.5,\n",
        "                maximum=1.0,\n",
        "                value=0.85,\n",
        "                step=0.05,\n",
        "            )\n",
        "\n",
        "            foreground_ratio.change(\n",
        "                update_foreground_ratio,\n",
        "                inputs=[img_proc_state, foreground_ratio],\n",
        "                outputs=[background_remove_state, preview_removal],\n",
        "            )\n",
        "\n",
        "            run_btn = gr.Button(\"Run\", variant=\"primary\", visible=False)\n",
        "\n",
        "        with gr.Column():\n",
        "            output_3d = LitModel3D(\n",
        "                label=\"3D Model\",\n",
        "                visible=False,\n",
        "                clear_color=[0.0, 0.0, 0.0, 0.0],\n",
        "                tonemapping=\"aces\",\n",
        "                contrast=1.0,\n",
        "                scale=1.0,\n",
        "            )\n",
        "    examples = gr.Examples(\n",
        "        examples=example_files,\n",
        "        inputs=input_img,\n",
        "    )\n",
        "\n",
        "    input_img.change(\n",
        "        requires_bg_remove,\n",
        "        inputs=[input_img, foreground_ratio],\n",
        "        outputs=[\n",
        "            run_btn,\n",
        "            img_proc_state,\n",
        "            background_remove_state,\n",
        "            preview_removal,\n",
        "            output_3d,\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    run_btn.click(\n",
        "        run_button,\n",
        "        inputs=[\n",
        "            run_btn,\n",
        "            input_img,\n",
        "            background_remove_state,\n",
        "            foreground_ratio,\n",
        "        ],\n",
        "        outputs=[\n",
        "            run_btn,\n",
        "            img_proc_state,\n",
        "            background_remove_state,\n",
        "            preview_removal,\n",
        "            output_3d,\n",
        "        ],\n",
        "    )\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w03L09UOGrOb",
        "outputId": "ce6cc0d0-6b1b-4bcc-c83b-90063cbbdc01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python app.py"
      ],
      "metadata": {
        "id": "lGfldGskWHzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a3e453-5e54-4146-b662-95cdb914fd49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio_client/utils.py:1097: UserWarning: file() is deprecated and will be removed in a future version. Use handle_file() instead.\n",
            "  warnings.warn(\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://cbbd013e76ee97bd36.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2710, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stable-fast-3d/app.py\", line 323, in <module>\n",
            "    demo.launch(share=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2615, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2714, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/http_server.py\", line 68, in close\n",
            "    self.thread.join(timeout=5)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1100, in join\n",
            "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7860 <> https://cbbd013e76ee97bd36.gradio.live\n"
          ]
        }
      ]
    }
  ]
}